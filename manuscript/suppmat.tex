\documentclass{article}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage[labelfont=bf]{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{xcite}
\usepackage{amsmath}
\usepackage{natbib}

\renewcommand{\textfraction}{1.0}
\renewcommand{\floatpagefraction}{.9}
\newcommand\revised[1]{\textcolor{red}{#1}}
\renewcommand{\topfraction}{0.9}    % max fraction of floats at top
\renewcommand{\bottomfraction}{0.8} % max fraction of floats at bottom
\renewcommand{\textfraction}{0.07}  % allow minimal text w. figs

\makeatletter 
\renewcommand{\thefigure}{S\@arabic\c@figure} 
\renewcommand{\thetable}{S\@arabic\c@table} 

\externalcitedocument{pooled_error}

\usepackage{url}
\urlstyle{same}

\begin{document}

\begin{titlepage}
\vspace*{3cm}
\begin{center}

{\LARGE
Overcoming confounding plate effects in differential expression analyses of single-cell RNA-seq data
\par}

\vspace{0.75cm}

{\Large 
    \textsc{Supplementary Materials}
\par
}
\vspace{0.75cm}

\large
by

\vspace{0.75cm}
Aaron T. L. Lun$^{1}$ and John C. Marioni$^{1,2}$

\vspace{1cm}
\begin{minipage}{0.9\textwidth}
\begin{flushleft} 
$^1$Cancer Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom \\[6pt]
$^2$EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom \\[6pt]
\end{flushleft}
\end{minipage}

\vspace{1.5cm}
{\large \today{}}

\vspace*{\fill}
\end{center}
\end{titlepage}

%\onehalfspacing

\begin{color}{red}
\section{Details on the simulation design}

\subsection{Overview}
We simulate from a NB-log-normal mixture, where the counts are conditionally NB-distributed and the plate effect is log-normally distributed.
For count $Y_{ij}$ of gene $i$ in cell $j$ in plate $k$ of group $g$, we assume that
\[
    Y_{ij} | \delta_{ik}, \theta_j \sim \mbox{NB}(\delta_{ik}\theta_j\mu_{ig}, \varphi_i)
\]
where $\theta_j$ is the cell-specific bias, $\delta_{ik}$ is the plate effect, $\mu_{ig}$ is the expected read count for this gene in group $g$, and $\varphi_i$ is the NB dispersion for this gene.
All counts are assumed to be conditionally independent.
We assume that $\log(\delta_{ik})$ is normally distributed with variance $\sigma^2$ and mean $-\sigma^2/2$.
This parametrization means that $E(\delta_{ik}) = 1$, i.e., the plate effect for each gene averages out across many plates.
Similarly, $\theta_j$ is sampled from some distribution with a mean of unity (i.e., the bias averages out across many cells) and is independent of $\delta_{ik}$.
Having means of unity for both $\theta_j$ and $\delta_{ik}$ is not strictly necessary, but simply ensures that the mean count across all cells and plates in group $g$ will be $\mu_{ig}$, consistent with its definition as an expectation.

\subsection{Parameter estimation from real data}
We designed our simulation to mimic the characteristics of the mESC data set \citep{kolod2015single}.
This required some pre-processing to remove irrelevant genes and cells from the data prior to parameter estimation.
Specifically, low-abundance genes with average counts below 1 were filtered out.
Also, cells were only used if they belonged to a batch that contained all three culture types, i.e., serum, a2i and 2i.

We then estimated the simulation parameters from the data.
For the cell-specific biases, we applied the deconvolution method \citep{lun2016pooling} where all cells corresponding to each culture type were defined as a cluster.
This yielded size factors centered around unity (Figure~\ref{subfig:realsize}), which can be treated as estimates of $\theta_j$ for all cells.
To estimate the mean count of each gene, we fitted an intercept-only GLM to the counts from all cells, using the mglmOneGroup function in edgeR with mean-centered log-size factors as offsets.
The resulting coefficient was used to define $\mu_{i0}$, i.e., the expected count of gene $i$ (Figure~\ref{subfig:realmean}).
For non-DE genes, $\mu_{ig}$ was set to $\mu_{i0}$ for all groups, whereas for DE genes, $\mu_{ig} = \psi_{ig}\mu_{i0}$ for some fold change $\psi_{ig}$.
Finally, we used the estimateDisp function in edgeR to estimate the NB dispersion.
As the NB distribution is conditional on the plate-specific mean, we treated each plate as a separate group during GLM fitting and dispersion estimation.
The ``tagwise'' dispersion estimate was used as $\varphi_i$ for each gene (Figure~\ref{subfig:realdisp}).

\begin{figure}[p]
    \begin{minipage}{0.49\textwidth}
        \includegraphics[width=\textwidth]{../reference/results_ESpresso/libsizes.pdf}
        \subcaption[]{}
        \label{subfig:realsize}
    \end{minipage}
    \begin{minipage}{0.49\textwidth}
        \includegraphics[width=\textwidth]{../reference/results_ESpresso/avecounts.pdf}
        \subcaption[]{}
        \label{subfig:realmean}
    \end{minipage}
    \begin{minipage}{0.49\textwidth}
        \includegraphics[width=\textwidth]{../reference/results_ESpresso/celldisp.pdf}
        \subcaption[]{}
        \label{subfig:realdisp}
    \end{minipage}
    \begin{minipage}{0.49\textwidth}
        \includegraphics[width=\textwidth]{../reference/results_ESpresso/platevar.pdf}
        \subcaption[]{}
        \label{subfig:realplate}
    \end{minipage}
    \caption{Estimates of the simulation parameters from the mESC data set.
        (\subref{subfig:realsize}) Histogram of size factors across all cells.
        (\subref{subfig:realmean}) Histogram of log-mean counts across all genes.
        (\subref{subfig:realdisp}) Gene-specific dispersion estimates, plotted against the log-means for all genes.
        (\subref{subfig:realplate}) Histogram of the estimated variances of the plate effect across all genes, where the red line indicates the average (estimated at 0.32 in this data set).
    }
\end{figure}

To estimate the variability of the plate effect, we fitted a GLMM to the counts for each gene using the glmer function in the lme4 package \citep{bates2015fitting}.
We set the culture type and batch as fixed effects, the plate of origin as a random effect, and log-size factor as the offset for each cell.
The distribution family was set to a NB distribution, where the ``theta'' parameter was defined as $\varphi_i^{-1}$ for gene $i$.
After fitting, the estimated variance of the random effect was obtained with the VarCorr function (Figure~\ref{subfig:realplate}).
As the NB GLMM uses a log link function, this estimate represents the variance of the log-transformed plate effect and thus can be used as $\sigma^2$ in our simulation.
However, each gene-specific estimate will be unstable with small numbers of plates.
We improved precision by using the average estimate across all genes as $\sigma^2$.
Note that the large number of zeroes in Figure~\ref{subfig:realplate} is likely caused by applying non-negativity constraints to unstable estimates, and does not indicate that the true variance of the plate effect is zero for those genes. 

As an alternative to the NB model, we fitted a zero-inflated NB (ZINB) distribution to the counts for each gene.
This was done using the zeroinfl function from the pscl package \citep{zeilis2008regression}.
The plate of origin was used as a factor for the NB component, whereas a common zero component was used for all cells to simplify regression.
Offsets were defined as log-transformed size factors.
For the NB component, the mean count was computed for each plate and the grand mean $\mu_{i0}'$ across plates was computed for each gene.
The NB dispersion $\varphi_i'$ and the probability $p'_i$ of belonging to the zero component were also estimated for each gene.
These values were used to redefine the sampling distribution of $Y_{ij}$ as a ZINB distribution.
Specifically, the mean of the NB component was set to $\delta_k\theta_j\mu_{i0}'$, the dispersion was set to $\varphi_i'$ and the zero probability was set to $p'_i$.
(For simplicity, we do not consider DE when simulating ZINB counts.)

\subsection{Defining simulation scenarios}
We simulated data for a scRNA-seq experiment with two groups of three plates.
The number of cells on each plate was sampled from a Uniform$(50, 100)$ distribution.
The bias $\theta_j$ for each cell was similarly sampled from the set of size factor estimates.
We then randomly selected 10000 genes from the mESC data set.
(For assessing type I error control, all genes are non-DE such that the null hypothesis is true for each gene.)
For each chosen gene, the plate effect $\delta_{ik}$ in plate $k$ was sampled from a log-normal distribution.
This, along with the mean and dispersion of the chosen gene, was used to define the sampling distribution of $Y_{ij}$ for each cell on the plate.
We repeated this process for each plate to obtain counts for all genes in all cells.

We tested different scenarios by repeating the simulation with modified parameters.
To reduce the variability of the plate effect, we halved the estimate of $\sigma^2$ prior to sampling $\delta_{ik}$.
Similarly, we set $\sigma^2=0$ to generate data where the plate effect was completely absent.
We increased the variability in the number of cells per plate, by sampling the number per plate from a Uniform$(20, 100)$ distribution.
We also increased the variability in the size factors, by multiplying each size factor by $2^{V_j}$ where $V_j \sim \mbox{Normal}(0, 0.25)$.
We replaced the NB distribution with a ZINB distribution (with parameters estimated from real data, as previously described) for count sampling.
Finally, we increased the size of the data set by using six plates per group.

To evaluate power and FDR control, we repeated the simulation with incorporation of DE genes.
We chose a random subset of $G$ genes for which DE was to be introduced.
This was then partitioned into two further subsets of equal size.
The first subset was upregulated in the first group such that $\psi_{i1} = \sqrt{\psi_0} = \psi_{i2}^{-1}$ for each gene $i$ in this subset.
The $\psi_0$ term represents the overall fold change between groups and is set to some value greater than unity.
By comparison, the second subset of genes was downregulated such that $\psi_{i2} = \sqrt{\psi_0} = \psi_{i1}^{-1}$ for each gene.
We performed these simulations with $\psi_0 =3$ and $G=2000$ by default.
However, we also tested additional scenarios, such as setting $\sigma^2=0$ to eliminate the plate effect; increasing $\psi_0$ to 6 to obtain stronger DE fold changes; or increasing $G$ to 4000 to obtain more DE genes.

In all scenarios, we added balanced DE (i.e., an equal amount of up-/downregulation) to avoid introducing composition bias \citep{robinson2010scaling}.
This simplifies the downstream analyses as it means that library size normalization can be used with all methods.
Thus, any difference in performance between analyses cannot be attributed to a difference in normalization accuracy for single-cell or summed counts.
This is an important subtlety, as bulk normalization methods fare poorly on scRNA-seq data with many zero counts \citep{lun2016pooling}.
If these methods are used, they may contribute to the loss of error control.
\end{color}

\section{Detailed description of the DE analysis}

\subsection{Implementation of the analysis methods}
For edgeR v3.12.0, DE analyses were performed with and without EB shrinkage.
In the first analysis, an abundance-dependent trend was fitted to the NB dispersions, and the trended NB dispersion was used to fit a \revised{GLM} for each gene \citep{mccarthy2012differential}.
The GLM deviance was used to estimate the QL dispersion for each gene, which was stabilized by robust EB shrinkage towards a mean-QL dispersion trend \citep{lund2012detecting}.
DE testing between groups was performed using the QL F-test \revised{with the shrunken dispersions}.
In the second analysis, the NB dispersion was estimated for each gene individually.
This was used directly to fit the GLM for each gene, and DE testing for each gene was performed using the LRT.

For voom, all counts were converted to log-CPM values and precision weights were computed from a fitted mean-variance trend.
A linear model was fitted to the log-CPMs and weights for each gene using methods in the limma package v3.26.3.
Sample variances were stabilized by EB shrinkage, and genes were tested for DE between groups using a moderated $t$-test.
This analysis was also repeated after using the duplicateCorrelation function \citep{smyth2005use} to estimate the correlations introduced by the plate effects.
For each gene, this correlation refers to the strength of the association between the count for each cell and the plate of origin for that cell.
The consensus correlation across all genes was estimated and incorporated into the linear model by blocking on the plate of origin for all cells.
DE testing was then performed on this refitted model.

For DESeq2 v1.10.1, the NB dispersion was estimated for each gene and a mean-dispersion trend was fitted across genes.
A normal prior was applied to the log-dispersions for all genes, and the maximum \textit{a posteriori} estimate of the NB disperison was obtained for each gene.
The estimated dispersion was used to fit a GLM to the counts for each gene.
DE testing was performed between groups using the Wald test.

For Monocle v1.4.0, counts were transformed into CPM values that were considered to be roughly log-normal.
These were used for DE testing between groups with the LRT in the differentialGeneTest function.

For MAST v0.933, counts were converted into log-CPMs after adding a prior count of 1.
For each gene, a hurdle model was fitted to the log-CPMs across all cells. 
The group was used as the factor of interest and the proportion of genes with non-zero counts in each library was used as an additional covariate \citep{finak2015mast}.
The fitting method was set to ``bayesglm'' and EB shrinkage was turned on with the ``MLE'' method and the ``H1'' model.
Putative DE genes between groups were identified using the LRT.

\revised{The glmer.nb function in the lme4 package v1.1-10 was used to fit a NB GLMM to the counts for each gene.
The group was set as a fixed effect while the plate of origin was set as a random effect.
Offsets were defined as the log-transformed library sizes.
To detect DE between groups, the GLMM was refitted using a null design without the group factor.
A LRT was then performed using the full and null model fits.}

\subsection{Explanation of the normalization strategy}
\begin{color}{red}
For any given set of counts, the same normalization procedure was used for all analyses.
For simulated data, size factors were defined as mean-adjusted library sizes.
This is possible due to the presence of balanced DE, as previously described.
For real single-cell data, size factors were computed with the deconvolution method.
To mitigate any DE, cells were clustered into relevant clusters (e.g., by culture type in the mESC data set) prior to normalization.
For real summed or bulk data, size factors were defined using the DESeq normalization method \citep{anders2010differential}.
In each scenario, size factors were either used directly (e.g., in the DESeq2 analysis) or converted into effective library sizes to compute offsets or CPM values.
The conversion was performed by scaling each size factor by the average of the original sizes across all cells.
This preserves the relative normalization between cells while recovering the scale of the original library sizes.

It is worth elaborating on what normalization actually does to the count sums.
For each plate, the bias in the count sum is equal to the sum of the cell-specific biases across all cells on the plate.
This is based on the pooling normalization framework in \cite{lun2016pooling}, after a slight modification by setting $t_j$ to 1 for each cell $j$.
Normalization on the count sums will subsequently eliminate this plate-specific bias, such that there will be no systematic differences in the count sums of non-DE genes between plates.
\end{color}

\begin{color}{red}
\begin{figure}[p]
    \begin{center}
        \includegraphics[height=4in]{../simulations/ESpresso/results_failsim/supp_raw.pdf}
    \end{center}
    \caption{    
        Observed type I error rates for each method on simulated data upon halving the variability of the plate effect; increasing the variability in the number of cells per plate; increasing the variability in library sizes across cells; using a ZINB distribution to sample counts; and increasing the number of plates in each group.
        Error rates are shown on a log scale and represent the average across 10 simulation iterations.
        Each error bar represents the standard error of the log-average rate.
        The threshold of 0.01 is represented by the red line.
        Only one iteration was used for Monocle and GLMMs due to their long running times.
    }
    \label{fig:extrafail}
\end{figure}

\begin{figure}[p]
    \begin{center}
        \includegraphics[height=4in]{../simulations/ESpresso/results_failsim/supp_sum.pdf}
    \end{center}
    \caption{   
        Observed type I error rate for each method after summation in a variety of simulation scenarios (see Figure~\ref{fig:extrafail}).
        Error rates are shown on a log scale and represent the average across 10 simulation iterations.
        Error bars represent standard errors, and the threshold of 0.01 is represented by the red dashed line.
    }
\end{figure}

\begin{figure}[p]
    \begin{center}
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\textwidth]{../simulations/ESpresso/results_power/ROC_2.pdf}
        \subcaption[]{}
        \label{subfig:noplate}
    \end{minipage}
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\textwidth]{../simulations/ESpresso/results_power/ROC_3.pdf}
        \subcaption[]{}
        \label{subfig:bigfc}
    \end{minipage}
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\textwidth]{../simulations/ESpresso/results_power/ROC_4.pdf}
        \subcaption[]{}
        \label{subfig:morede}
    \end{minipage}
    \end{center}
    \caption{  
        ROC curves for each analysis method using single-cell (full) and summed counts (dashed), in simulations with (\subref{subfig:noplate}) no plate effect, (\subref{subfig:bigfc}) larger DE fold changes and (\subref{subfig:morede}) more DE genes. 
        Curves are shown for DESeq2 (black), voom (grey) and QL edgeR (red).
        Each curve represents the average of 10 iterations.
    }
    \label{fig:altroc}
\end{figure}

\begin{figure}[p]
    \begin{center}
        \includegraphics[height=4in]{../simulations/ESpresso/results_power/FDR.pdf}
    \end{center}
    \caption{
        Observed FDRs for each analysis method using single-cell or summed counts in simulations with DE genes and a plate effect (denoted above as ``Plate effect'').
        Settings for additional simulation scenarios are equivalent to those used in Figure~\ref{fig:altroc}.
        The red line represents the nominal threshold of 5\%.
        All values represent the average of 10 simulation iterations, and error bars represent the standard error.
    }
\end{figure}
\end{color}

\section{Summation and plate-specific mean variance relationships}
\revised{Data sets will contain different numbers of cells in each plate, as well as different library sizes across cells.
This means that the count sum for each plate will not be identically distributed.
The most obvious difference is observed in the magnitude of the count sum between plates with different numbers of cells or library sizes per cell.
This leads to a consistent fold-difference in the expression of all genes on one plate relative to another, which can be resolved by normalizing on the total library size for each plate (i.e., the sum of count sums across genes) or with related methods.
The greater problem is that the count sum for each plate will not have the same mean-variance relationship.
Briefly, the variance of a random variable can be expressed as a function of its mean.
Most parametric models assume that this function is the same for all observations of a given gene.
For example, standard edgeR and DESeq2 analyses use a single NB dispersion estimate for each gene, which defines an identical mean-variance relationship for all counts of that gene.
However, if the count sum for each plate has a different relationship, the accuracy of the models may be compromised.}

\revised{In practice, differences in library sizes across cells and/or numbers of cells across plates do not seem to negatively affect the performance of methods on summed counts.
Power and error control are maintained in our simulations with variable library sizes and cell numbers.}
The robustness of summation can be explained by examining the mean-variance relationship of the simulated data.
\revised{For simplicity, partition the cells on plate $k$ into $L_k$ bins where all cells in bin $l$ are assigned the same cell-specific bias $\theta_l$.
(This does not affect generality, as any number of arbitrary bins can be defined.)}
Let $\lambda_{il} = \delta_{ik}\theta_{l}\mu_{ig}$ for gene $i$ in each cell of \revised{bin} $l$.
The count for each cell is independently sampled from a NB distribution with mean $\lambda_{il}$ and dispersion $\varphi_i$, as described in the simulation design.
The conditional variance of the count sum $S_{ik}$ for plate $k$ is then
\[
    \mbox{var}(S_{ik} | \delta_{ik}) = \sum_{l} N_l \lambda_{il}  + \varphi_{i} \sum_{l} N_l \lambda_{il}^2 \;.
\]
Given that $E(S_{ik}) = E(\sum_l N_l\lambda_{il}) = \sum_l N_l \theta_l \mu_{ig}$, the variance of the count sum can be decomposed to
\begin{align*}
    \mbox{var}(S_{ik}) 
    &= \mbox{var}\{E(S_{ik} | \delta_{ik} ) \} + E\{ \mbox{var}(S_{ik} | \delta_{ik}) \}\\
    &= \mbox{var}\left(\delta_{ik}\sum_l N_l \theta_{l}\mu_{ig}\right) + E\left(\delta_{ik}\sum_l  N_l\theta_l\mu_{ig}  + \varphi_{i} \delta_{ik}^2 \sum_l  N_l\theta_l^2\mu_{ig}^2\right)\\
    &= \left(\sum_l N_l \theta_{l}\mu_{ig} \right)^2 \mbox{var}(\delta_{ik}) + \left(\sum_l N_l \theta_{l}\mu_{ig}\right) + \left( \varphi_i \sum_l  N_l\theta_l^2\mu_{ig}^2 \right) E(\delta_{ik}^2) \\
    &= E(S_{ik})^2 \mbox{var}(\delta_{ik}) + E(S_{ik}) + \left\{ \varphi_i \frac{\sum_l N_l \theta_j^2\mu_{ig}^2}{ (\sum_l N_l \theta_j\mu_{ig})^2}  \right\} E(S_{ik})^2 E(\delta_{ik}^2) \;. 
\end{align*}
\revised{Note} that $E(\delta_{ik}^2)$ and $\mbox{var}(\delta_{ik})$ are constant for all plates.
This means that\revised{, in the above expression,} only the third term defines the plate-specific aspect of the mean-variance relationship.
Now, consider the behaviour of this term as the number of cells increases.
If $N_l$ increases in each of $b$ \revised{bins}, the limit becomes
\[
    \lim_{\substack{N_{l_1} \to \infty \\ \dots \\ N_{l_b} \to \infty}} \frac{\sum_l N_l \theta_j^2\mu_{ig}^2}{ (\sum_l N_l \theta_j\mu_{ig})^2} 
    = \sum_l \lim_{\substack{N_{l_1} \to \infty \\ \dots \\ N_{l_b} \to \infty}} \frac{N_l \theta_j^2\mu_{ig}^2}{ (\sum_l N_l \theta_j\mu_{ig})^2} 
= 0
\]
for positive values of $\theta_j$ and $\mu_{ig}$.
This means that, for any non-zero value of $\mbox{var}(\delta_{ik})$, the relative contribution of the plate-specific term will approach zero as the number of cells increases.
Thus, the mean-variance relationship of the count sum will be similar across plates with many cells, regardless of the number or library sizes of those cells.
Summation will be similarly robust to plate-specific values for the NB dispersion \revised{or subpopulation-specific values for the mean count.
Replacing $\varphi_i$ with some arbitrary $\varphi_{ik}$, or $\mu_{ig}$ with some subpopulation-specific expression $\mu_{il}$, will also have little effect as the plate-specific term approaches zero.}

%While this result is described for discrete subpopulations of cells with the same $\theta_l$, it can also be generalized to a more continuous distribution of cells (and specifically, of $\theta_l$) by considering an arbitrarily large $L_k$ on the plate.

% If you take the simulation mean of exp(5), that gives us a dispersion around 1.2. Summing across 10 cells brings this down to 0.12.
% Now, the variance of the plate effect is around 0.6 (not 0.5, as that's the log-plate effect), so you can see that it dominates the relationship.

% Also note that just adding more cells doesn't guarantee that it'll drop to zero, because you could add a huge cell and the relationship would then 
% be dominated by that cell in a plate-specific manner. This is a bit pathological, true, but nonetheless, it's possible.

\section{Benefits of hiding the variability between cells}
If more cells contribute to the sum, variability between cells will be hidden as it will no longer affect the total variance.
However, this is not undesirable for single-cell analyses.
Genes with reproducible DE between plates should not be penalized for having high variability within plates, e.g., due to cellular heterogeneity or the presence of subpopulations.
This philosophy is almost the exact opposite of that in microarray analyses involving technical replicates,
    where variability between replicates is explicitly modelled rather than being hidden by averaging the replicate signals \citep{smyth2005use}.
The difference in strategies is due to the fact that the technical replicates in microarray analyses are expected to be similar.
Genes with large differences between replicates are considered to be unreliable and should have reduced significance for DE.
In contrast, cells are not expected to be similar due to biological heterogeneity within populations.
Large cell-to-cell variability has no bearing on the reliability of DE between populations when many cells are present.
For example, if the subpopulation structure is the same in each replicate plate, one would have a situation with large variability between cells in different subpopulations but reproducible count sums across plates.

%\revised{On a related note, the subpopulation structure can also affect the independence of the count sums.}
%If the proportion of cells in each subpopulation is the same across replicate plates, the count sums for these plates will be \revised{correctly modelled as independent values} in a one-way layout.
%This is because the count sum for each plate in a given group will have the same expectation \revised{after adjusting for total library size of each plate}.
%Each count sum can be considered to be independently sampled from a distribution with this \revised{expectation}, due to the independence of $\delta_{ik}$ and conditional independence of the counts.
%However, this will not be true if the proportion of cells in each subpopulation is different across replicate plates.
%In such cases, the mean for each count sum will vary for each plate in a gene-specific manner that cannot be resolved by scaling normalization.
%Attempting to model the count sums with a group-specific mean will lead to hidden dependencies between plates, akin to those between cells when plate effects are ignored.
%This situation is arguably pathological as plates with \revised{systematic differences in the subpopulation structure} should not be \revised{treated as} replicates.

% It's independent because information about subpopulation-specific expression is absorbed into the mean of the count sum already. 
% We also assume that the cell-specific bias is a random variable, which also goes away upon taking the expectation.

\begin{figure}[p]
\begin{center}
    \includegraphics[width=0.6\textwidth]{../realdata/ESpresso/real_ranks.pdf}
\end{center}
\caption{
    Difference in ranks between DE analyses on single-cell and summed counts, for key pluripotency factors listed in Figure S5 of \cite{kolod2015single}.
    For each comparison between culture types, the rank for each gene was obtained from the DE lists of QL edgeR using either summed or single-cell counts.
    A positive difference in ranks means that the gene is lower ranked (i.e., further down the list) in the single-cell analysis compared to the summed analysis.
    The minimum rank is the smaller rank from either analysis, and represents the ``best'' position of each gene.
    The grey bar marks a difference in ranks of $\pm100$.
    The difference in the enrichment of factors in the top 250 genes between summed and single-cell analyses was tested using Fisher's exact test, yielding a $p$-value of $1.9 \times 10^{-4}$ (using total numbers of genes across both comparisons). 
}
\end{figure}

\begin{figure}[p]
    \begin{center}
        \includegraphics[width=\textwidth]{../realdata/ESpresso/top_edgeR_3_sum.pdf}
        \includegraphics[width=\textwidth]{../realdata/ESpresso/top_edgeR_4_sum.pdf}
    \end{center}
\caption{
    Expression profiles of DE genes between 2i and serum (top) or between a2i and serum (bottom) in the mESC data set, for the top genes detected by QL edgeR on summed counts.
    Each plot contains the expression profile for a gene \revised{in terms of log-CPMs}, where each point represents a cell in the serum (black) or a2i/2i \revised{groups} (grey).
    A prior of 0.25 was added to each count to avoid undefined log-CPMs from zeroes.
}
\label{fig:realdata}
\end{figure}

% The second kolod comparison is the only one with decent DE for all methods,
% which is why it's being used here.
 
\end{document}
